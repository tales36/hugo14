---
title: "CMP304_AWS_infrastructure_For_Large_scale_Distributed_Training_At_Facebook_AI"
date: 2019-12-06T11:20:40+09:00
author: "katsutoshi miyata"
tags: ["勉強系","AWS re:invent2019"]
cover: ../../img/awsreinvent2019.jpg
---

## ■はじめに
### ◆深層学習は特異である。
・他のメソッドに比べ正確な情報に辿り着ける。  
・imagenet に比べてもInstagramの方が正確な画像に辿り着ける。

### ◆FacebookでのMLの規模と成長
MLのワークフローは以下。

>[データ] → [モデル成形] → [トレーニング] → [評価・査定] → [デプロイ]

デプロイ内容をまたデータとしてMLを回したり、評価・査定結果で信頼性が低いものを再びモデル成形に戻して、学習内容の正確性を高めていく。

なお、学習させている内容はランキングとレコメンド作成がほとんどで、最も重要視している。
他にもコンピュータービジョン、言語を学習させてるが全体の数％程度。

### ◆トレーニングワークロードの特徴
それぞれのモデルによって利用するリソースが違う。
ランキングとレコメンド作成はメモリをよく使うが、コンピュータービジョンではCPUをレコメンドよりも使用する。

## ■深層学習のインフラについて
### ◆インスタンス
P3/P3dnインスタンスは機械学習に最適  
　→GPUからGPUへプライオリティパスが使える為、並列稼働させた時やデータの受け渡しをする場合の速度がダンチ。  
　　→EFAが100Gbpモデル平行稼働にも対応しているので。

### ◆Framework
PyTorch  
TensorFlow  
mxnet  
の三つを使用している。

### Interface
Gluon  
Keras

の二つを使用。

### ◆GPUの数と深層学習速度のグラフ。
Andy Jassyの基調講演で見たやつ。
8GPUだと9日と8時間かかる学習が2048GPUだと1時間で済む。

## ■感想
Facebookでよく出てくる「この人友達？」などで使ってるエンジンの中身のセッションでした。  
利用状況やプロフィールとかを利用してやってるんだから、SNSサービスはビッグデータを余すことなく使えて楽しそう。(倫理観は置いといて)  

弊社だと便所利用状況のデータ毎日取ってるんだから、深層学習で行けるタイミングをレコメンドさせる"深便(フカベン)"というのを作ってみては如何だろうか。